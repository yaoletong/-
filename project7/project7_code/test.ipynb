{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T17:37:41.480975Z",
     "start_time": "2024-06-22T17:37:36.215198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "    SOURCE: -f\n",
      " PREDICTED: \"   "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from config import get_config, latest_weights_file_path\n",
    "from train import get_model, get_ds, run_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T17:37:51.726465Z",
     "start_time": "2024-06-22T17:37:41.479069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Max length of source sentence: 220\n",
      "Max length of target sentence: 210\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "print(\"Using device:\", device)\n",
    "config = get_config()\n",
    "train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
    "model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
    "\n",
    "# Load the pretrained weights\n",
    "model_filename = latest_weights_file_path(config)\n",
    "state = torch.load(model_filename)\n",
    "model.load_state_dict(state['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T17:37:56.406282Z",
     "start_time": "2024-06-22T17:37:51.727366Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stty: stdin isn't a terminal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Digué: -Us agraden les rates?\n",
      "    TARGET: He said: \"Do you love rats?\"\n",
      " PREDICTED: He said : \" You don ' t want you done ?\"\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: -O Tom! Poden veure en la foscor, igual que els gats.\n",
      "    TARGET: \"Oh, Tom, they can see in the dark, same as cats.\n",
      " PREDICTED: \" Oh , Tom , they can see in the dark , same as cats .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: -I després… i després… Bé, no n'estic cert, pero em sembla com si haguéssiu manat a Sid que se n'anes i…i…i… -I que?\n",
      "    TARGET: \"And then--and then--well I won't be certain, but it seems like as if you made Sid go and--and--\" \"Well?\n",
      " PREDICTED: \" And then -- and then -- well I won ' t be certain , but it seems like as if you made Sid go and -- and -- and --\" \" Well ?\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Els minyons feren allo que havien fet ben sovint altres vegades: anaren a la reixa de la cel·la, i donaren a Potter tabac i mistos.\n",
      "    TARGET: The boys did as they had often done before--went to the cell grating and gave Potter some tobacco and matches.\n",
      " PREDICTED: The boys did as they had often done before -- went to the grating and gave Potter some tobacco and matches .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: I aixo no és res!\n",
      "    TARGET: And that ain't all.\n",
      " PREDICTED: And that ain ' t all .\n",
      "--------------------------------------------------------------------------------\n",
      "bleu_total: BLEU = 0.49 2.2/0.6/0.3/0.2 (BP = 1.000 ratio = 18.600 hyp_len = 93 ref_len = 5)\n"
     ]
    }
   ],
   "source": [
    "run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: print(msg), 0, None, num_examples=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
